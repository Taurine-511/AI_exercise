# --------------------
# Logging
# --------------------
use_wandb: true
project: "Spot_difference_VLM"
run_name: "test"

# --------------------
# Model
# --------------------
model_name: "unsloth/Qwen2.5-VL-7B-Instruct"
max_seq_length: 32768
load_in_4bit: true
fast_inference: true
gpu_memory_utilization: 0.8

# --------------------
# LoRA
# --------------------
finetune_vision_layers: false
finetune_language_layers: true
finetune_attention_modules: true
finetune_mlp_modules: true

r: 16
lora_alpha: 16
lora_dropout: 0.0
random_state: 3407

# --------------------
# Training
# --------------------
learning_rate: 5e-6
adam_beta1: 0.9
adam_beta2: 0.99
weight_decay: 0.1
warmup_ratio: 0.1
lr_scheduler_type: "cosine"
optim: "adamw_8bit"
gradient_accumulation_steps: 1
num_generations: 8
max_prompt_length: 1024
max_completion_length: 1024
num_train_epochs: 2.0
max_grad_norm: 0.1
